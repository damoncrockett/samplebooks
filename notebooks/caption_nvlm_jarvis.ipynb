{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a574c3a8-bf38-45e9-9baa-fec96329d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade transformers==4.37.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7189058-93a3-43a7-bf04-491c820ab707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't even know if these are necessary, but most models have required them\n",
    "#!pip install einops accelerate timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c66edb-7523-40b6-995f-e37c70e860d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import math\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d0b788-7c03-49b9-bbb8-fe8d3beea390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_model():\n",
    "    device_map = {}\n",
    "    world_size = torch.cuda.device_count()\n",
    "    num_layers = 80\n",
    "    # Since the first GPU will be used for ViT, treat it as half a GPU.\n",
    "    num_layers_per_gpu = math.ceil(num_layers / (world_size - 0.5))\n",
    "    num_layers_per_gpu = [num_layers_per_gpu] * world_size\n",
    "    num_layers_per_gpu[0] = math.ceil(num_layers_per_gpu[0] * 0.5)\n",
    "    layer_cnt = 0\n",
    "    for i, num_layer in enumerate(num_layers_per_gpu):\n",
    "        for j in range(num_layer):\n",
    "            device_map[f'language_model.model.layers.{layer_cnt}'] = i\n",
    "            layer_cnt += 1\n",
    "    device_map['vision_model'] = 0\n",
    "    device_map['mlp1'] = 0\n",
    "    device_map['language_model.model.tok_embeddings'] = 0\n",
    "    device_map['language_model.model.embed_tokens'] = 0\n",
    "    device_map['language_model.output'] = 0\n",
    "    device_map['language_model.model.norm'] = 0\n",
    "    device_map['language_model.lm_head'] = 0\n",
    "    device_map['language_model.model.rotary_emb'] = 0\n",
    "    device_map[f'language_model.model.layers.{num_layers - 1}'] = 0\n",
    "\n",
    "    return device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3ca1164-660e-4067-ac15-e0dcafa4e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "\n",
    "def build_transform(input_size):\n",
    "    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c38de6e5-96dc-4130-9c92-b4b857f7cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4724ef75-1858-4e9b-b38a-2e278ee66bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    # calculate the existing image aspect ratio\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= min_num)\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    # find the closest aspect ratio to the target\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "    # calculate the target width and height\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    # resize the image\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size\n",
    "        )\n",
    "        # split the image\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    assert len(processed_images) == blocks\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    return processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57c38d75-4c5d-499b-a12e-39218ea63dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=12):\n",
    "    # Check if the input is a URL\n",
    "    if isinstance(image_file, str) and image_file.startswith(\"http\"):\n",
    "        response = requests.get(image_file)\n",
    "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "    else:\n",
    "        image = Image.open(image_file).convert('RGB')\n",
    "    \n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(img) for img in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    \n",
    "    return pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c8985a-8af0-4893-a8ab-64d7030570c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6053f003bf49fba8159ee42e564339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d80f4c9ae447b09970a8e9d469c147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_nvlm_d.py:   0%|          | 0.00/3.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ffbd64507c4ba59c137a42660912fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_intern_vit.py:   0%|          | 0.00/5.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/nvidia/NVLM-D-72B:\n",
      "- configuration_intern_vit.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/nvidia/NVLM-D-72B:\n",
      "- configuration_nvlm_d.py\n",
      "- configuration_intern_vit.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f865c0793be54bf0bcd025e1e27ffd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_nvlm_d.py:   0%|          | 0.00/19.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfee5ce205e44db08feb8c753da28a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_intern_vit.py:   0%|          | 0.00/15.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/nvidia/NVLM-D-72B:\n",
      "- modeling_intern_vit.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356d89f7616d44cb9185e75aed36d6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "conversation.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/nvidia/NVLM-D-72B:\n",
      "- conversation.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/nvidia/NVLM-D-72B:\n",
      "- modeling_nvlm_d.py\n",
      "- modeling_intern_vit.py\n",
      "- conversation.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6be5a8507a9442a8c486a7673437d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/151k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bb80ceefa44229ad021cae4973712a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c41891508d4f94bcffd874da8704b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00046.safetensors:   0%|          | 0.00/3.73G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc496463f5014573b44c76ca1af5161b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac53fcaa989476982fc93212bdc917b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f03cf6eab0498db696e656d13d72e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69536015ef004000bc1df9c53acde4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273a360e99454064b240d22210db49cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1a106aa0e64dcd916be5046e4be55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149741ee54444fc89456ee45e75af763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf1bb3722524e43a9721fc1aeb3a0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879151228a04495c8c4941bb3d9e8a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962afd4ae1bb43b3b0c4d3ed47d8eeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce54310624549e5924bb584e5cd6e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00012-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748964aa504442609ac9363624da4a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00013-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af36a91c7fd4dd3ba34a7afa9ccca15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00014-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782c2ef9603c408aa132cabbbd3aa154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00015-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aaf88bbc3a24d40bd881c6e6e2f4463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00016-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc53191f0155424291e7a532c06fe5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00017-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d59b9b4e6f491cbdb4f17f66ad24af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00018-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b852c0fd72fc44baa8d3bde37c38f2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00019-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcedaa7abdc04bea8f3fba68720c15d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00020-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af2f615ae8244afa3f2e049236498c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00021-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dff6adc04b44e0594e9493157ae6b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00022-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fbb85ac45b4f46b3ba2722a4a982de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00023-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf82ad3bf204fd7975b765f6377bff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00024-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b540e32bf3e04a588b6ba5b0269548eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00025-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5add397d9658457fbf30eaf70872fc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00026-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c5be6d464d459583f48bd37a7fc0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00027-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b3e2b666504dd09418494e090d84e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00028-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03ffdbc05164ae6ace3c8ed58f9a8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00029-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13743104f8904a7cb4ab97e85dc20c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00030-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185ff63b24c84121af6930b6ea96f355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00031-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4c8de028ff4ae3ba8e2f7dabb32767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00032-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c5b885336a48a4ac3f595f0d7f5e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00033-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fbad6302ad450fbb7f898df6db4db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00034-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46edd5b48f55454bb6cd34de182661d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00035-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc927925465648de8746c8e38439a8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00036-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4d6bc6e17b4c0ebe5fafac1bf98d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00037-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690a113785114b7c87415581de5d9d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00038-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b09b07611b42c6936cb16283f43f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00039-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89e2d545f2b46299bc6d5ba50497c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00040-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ce006c23c9420ead28f4ff322e252c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00041-of-00046.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b223ab7fae4839bde3c12f874901f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00042-of-00046.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effcb1c20106402a886cc8811b72f82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00043-of-00046.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07213141f2084de3a1a7ef0dfec885e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00044-of-00046.safetensors:   0%|          | 0.00/3.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d52e54e43464fc9852086a9f778d99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00045-of-00046.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa531a84412455381c2f415461fe136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00046-of-00046.safetensors:   0%|          | 0.00/3.53G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:407: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e521ed0bd2448a8c4c747db14342aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"nvidia/NVLM-D-72B\"\n",
    "device_map = split_model()\n",
    "model = AutoModel.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attn=False,\n",
    "    trust_remote_code=True,\n",
    "    device_map=device_map).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ba96fe2-c5f3-4bf4-aef4-dc581bb55e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82044c51c20446a392ceb175cfabfef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d905c424b9947a3b82945bd3f369b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b46ecdd106c412c9f27b16ccaf44c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de518aca79af4ae389064aac260fb545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, use_fast=False)\n",
    "generation_config = dict(max_new_tokens=1024, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9e632cd-fddd-49ee-8bf5-2c4fa432f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    " 'https://samplebook.photos/img/4786a.jpg',\n",
    " 'https://samplebook.photos/img/284v.jpg',\n",
    " 'https://samplebook.photos/img/3193c.jpg',\n",
    " 'https://samplebook.photos/img/948d.jpg',\n",
    " 'https://samplebook.photos/img/3191i.jpg',\n",
    " 'https://samplebook.photos/img/4788oo.jpg',\n",
    " 'https://samplebook.photos/img/2086d.jpg',\n",
    " 'https://samplebook.photos/img/4781r.jpg',\n",
    " 'https://samplebook.photos/img/5521n.jpg',\n",
    " 'https://samplebook.photos/img/2073cc.jpg',\n",
    " 'https://samplebook.photos/img/2085b.jpg',\n",
    " 'https://samplebook.photos/img/4782c.jpg',\n",
    " 'https://samplebook.photos/img/4783v.jpg',\n",
    " 'https://samplebook.photos/img/4912gg.jpg',\n",
    " 'https://samplebook.photos/img/304h.jpg',\n",
    " 'https://samplebook.photos/img/2078i.jpg',\n",
    " 'https://samplebook.photos/img/2077q.jpg',\n",
    " 'https://samplebook.photos/img/3192h.jpg',\n",
    " 'https://samplebook.photos/img/904x.jpg',\n",
    " 'https://samplebook.photos/img/4792b.jpg',\n",
    " 'https://samplebook.photos/img/5301p.jpg',\n",
    " 'https://samplebook.photos/img/5207j.jpg',\n",
    " 'https://samplebook.photos/img/1007p.jpg',\n",
    " 'https://samplebook.photos/img/17l.jpg',\n",
    " 'https://samplebook.photos/img/286t.jpg',\n",
    " 'https://samplebook.photos/img/287g.jpg',\n",
    " 'https://samplebook.photos/img/3189j.jpg',\n",
    " 'https://samplebook.photos/img/4911d.jpg',\n",
    " 'https://samplebook.photos/img/4785a.jpg',\n",
    " 'https://samplebook.photos/img/4793a.jpg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8083341-8495-494d-8d89-79f9f56bc95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'There are two objects in this image. One is a color checker, and the other is a photographic sample book, open to a page containing a photograph. Give a detailed description of the photograph.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32ef3099-1149-4fbb-81c4-1cea9763b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(url):\n",
    "    pixel_values = load_image(url, max_num=12).to(torch.bfloat16)\n",
    "    question = f'<image>\\n{prompt}'\n",
    "    response = model.chat(tokenizer, pixel_values, question, generation_config)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcc0f8d3-0896-437a-9c38-11590ed0647b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:407: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:407: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/4786a.jpg \n",
      " The photograph in the book is a black-and-white image of a landscape. The landscape is dominated by a large, rocky outcrop in the foreground, with a few smaller rocks scattered around it. The sky is clear, and there are no visible clouds. The photograph is labeled \"GEVAERT RIDAX 8\" in the bottom right corner. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/284v.jpg \n",
      " The photograph depicts a power station, specifically a substation. The substation is equipped with high-voltage power lines and transformers. The power lines are supported by tall metal towers, and the transformers are large, cylindrical, and white. The substation is enclosed by a fence, and the background features a hilly landscape. The photograph is in black and white, and the image quality is sharp and clear. The photograph is labeled \"VARILOR\" and \"WHITE GLOSSY,\" indicating the type of photographic paper used. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/3193c.jpg \n",
      " The photograph depicts a room with a chandelier hanging from the ceiling. The chandelier is the focal point of the image, and it is surrounded by various pieces of furniture, including a sofa, chairs, and a table. The room appears to be well-decorated, with framed pictures hanging on the walls and a potted plant in the corner. The overall atmosphere of the room is one of elegance and sophistication. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/948d.jpg \n",
      " The photograph depicts a serene landscape scene, likely taken in a forest or a park. The image is in black and white, giving it a timeless and classic feel. The photograph captures a grove of trees, with their trunks and branches prominently featured. The trees appear to be tall and slender, with some of them reaching up towards the sky, while others are slightly bent or angled. The foliage is dense, with leaves creating a canopy that filters the light, casting dappled shadows on the ground below. The ground is covered with grass and underbrush, and there are no visible signs of human presence, such as buildings or pathways. The overall composition of the photograph is balanced and harmonious, with the trees and foliage creating a natural frame around the scene. The photograph conveys a sense of tranquility and connection to nature. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/3191i.jpg \n",
      " The photograph depicts a fountain in a public square. The fountain is constructed of stone and features a cascading water display. The water is captured in mid-flow, creating a sense of movement and energy in the image. The fountain is surrounded by a paved area, and in the background, there are buildings with classical architectural elements, such as columns and arches. The overall atmosphere of the photograph is one of tranquility and historical significance. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/4788oo.jpg \n",
      " The photograph depicts a man in a black and white image. He is wearing a hat and a suit, and he is smoking a pipe. The photograph is in a book, and the page is labeled \"ADLUX.\" \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/2086d.jpg \n",
      " The photograph depicts a man and a woman in a close embrace, with the man's head slightly tilted back and the woman's head resting on his chest. The man's left hand is positioned on the woman's back, while his right hand is raised, possibly to adjust his glasses. The woman's left hand is not visible, but her right hand is placed on the man's chest. The background of the photograph is not clearly visible, but it appears to be a dark, possibly blurred setting. The photograph is printed on Kodak Ektafine Paper X, as indicated by the label on the bottom right corner of the page. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/4781r.jpg \n",
      " The photograph depicts a man seated at a desk, with a pen in his right hand and a piece of paper in front of him. He is wearing a white shirt and a tie. The background is a plain wall, and there are no other objects in the image. The photograph is in black and white. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/5521n.jpg \n",
      " The photograph depicts a wine barrel, a cylindrical container used to store wine. The barrel is made of wood and has metal bands around it to hold the staves together. The photograph is in black and white, and the lighting is such that the barrel casts a shadow on the ground behind it. The photograph is printed on a page of the sample book, which is open to this page. The page is labeled \"Kodak Medalist Paper F\" and indicates that the photograph is available in both SW (slow-speed) and DW (double-weight) formats. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/2073cc.jpg \n",
      " The photograph in the book is a black-and-white aerial view of a prison. The prison is surrounded by a high wall, and there are several buildings within the compound. The buildings are arranged in a way that suggests a central courtyard or exercise area. The photograph is labeled \"KODAK BROMIDE BASED WATERPROOF PAPER.\" \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/2085b.jpg \n",
      " The photograph depicts a person standing on a surface covered with small rocks. The person is wearing a short-sleeved shirt and shorts. They are holding a stick in their right hand, which is raised above their head. The person's left hand is not visible in the photograph. The photograph is in black and white. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/4782c.jpg \n",
      " The photograph depicts a man seated on a boat. The boat is equipped with a sail, which is currently furled. The man is wearing a long, loose garment, and a turban or headscarf. He is holding onto the boat's railing with one hand, and there is a paddle resting on his lap. The background of the photograph shows a body of water, and the boat appears to be stationary. The photograph is in black and white, and the lighting suggests that it was taken during the day. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/4783v.jpg \n",
      " The photograph depicts a sculpture of an elephant, which is positioned in the foreground. The sculpture is made of a material that appears to be stone or a similar substance, and it is highly detailed, capturing the texture and form of the elephant. The sculpture is placed on a surface that is patterned with a grid of squares, which may be a part of the base or plinth on which the sculpture rests. In the background, there is a vase with a distinctive design, featuring a pattern of curved lines and shapes. The vase is positioned slightly to the left of the center of the image and is partially obscured by the elephant sculpture. The overall composition of the photograph is carefully arranged, with the objects placed in a way that creates a sense of balance and harmony. The lighting in the photograph is soft and even, highlighting the details of the sculpture and the vase without creating harsh shadows or reflections. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/4912gg.jpg \n",
      " The photograph depicts a dam, with water cascading over its crest. The dam is constructed of concrete and features a curved design, which is a common characteristic of such structures. The water flowing over the dam creates a misty effect, indicating the force and volume of the water. The photograph is in black and white, which adds a timeless quality to the image. The dam's structure and the water's movement are the main focal points of the photograph. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/304h.jpg \n",
      " The photograph depicts a man operating a printing press. The man is positioned to the right of the image, with his back facing the camera. He is wearing a white shirt and dark trousers. The printing press is a large, industrial machine with various levers, buttons, and dials. The machine is predominantly black, with some silver and metallic parts. The background of the image is a plain, light-colored wall. The photograph is in black and white, and the lighting is even, with no harsh shadows or bright highlights. The overall mood of the image is one of industry and hard work. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/2078i.jpg \n",
      " The photograph depicts a white object with a rounded top and a cylindrical base. The object is positioned against a plain background, which appears to be a gradient of light to dark gray. The lighting in the photograph is even, with no harsh shadows or highlights, suggesting the use of diffused light. The photograph is in black and white, which emphasizes the contrast between the object and the background. The object's surface appears smooth and slightly reflective, indicating that it may be made of a glossy material such as plastic or ceramic. The photograph is sharp and in focus, with clear details visible on the object's surface. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/2077q.jpg \n",
      " The photograph depicts a person standing on a snowy mountain. The person is wearing a hat and a long coat, and they are holding a walking stick. The mountain is covered in snow, and there are other mountains in the background. The sky is clear, and the sun is shining. The photograph is in black and white, and it has a vintage look to it. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/3192h.jpg \n",
      " The photograph depicts a scene viewed through an archway. The archway is constructed of stone and features a circular top. Beyond the archway, a tall, slender tower is visible in the distance. The tower is also made of stone and has a pointed top. The sky is partly cloudy, with patches of blue visible between the clouds. The ground in the foreground is covered with grass, and a path leads from the archway to the tower. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/904x.jpg \n",
      " The photograph depicts a winter scene, with snow blanketing the ground and trees. The trees are leafless, indicating that it is winter. The snow appears to be fresh, as there are no visible footprints or tire tracks. The sky is overcast, suggesting that it may continue to snow. The photograph is in black and white, giving it a timeless quality. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/4792b.jpg \n",
      " The photograph depicts a table with a white tablecloth, on which a black plate is placed. The plate is adorned with intricate patterns, and a black knife and fork are positioned on either side of the plate. The table is surrounded by chairs with a similar design, featuring a combination of straight and curved lines. The overall composition of the photograph is symmetrical, with the plate and utensils centered on the table. The black and white color scheme creates a stark contrast, highlighting the details of the objects. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/5301p.jpg \n",
      " The photograph depicts a woman with a vase on her head. The vase is adorned with a floral pattern, and the woman's hair is styled in an updo, with a few strands falling loose. She is wearing a necklace, and her expression is neutral. The background is blurred, with soft lighting that creates a dreamy atmosphere. The overall composition of the photograph is balanced, with the woman's head and the vase positioned in the center of the frame. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/5207j.jpg \n",
      " The photograph depicts a black-and-white image of a cat, which is the primary subject. The cat is positioned in the center of the image, with its head slightly tilted to the right. The cat's eyes are open and appear to be looking directly at the camera. The background of the image is blurred, with indistinct shapes and shadows that suggest an indoor setting. The photograph is printed on a high-quality paper that enhances the contrast and sharpness of the image. The overall composition of the photograph is balanced, with the cat's position and gaze drawing the viewer's attention to the center of the image. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/1007p.jpg \n",
      " The photograph depicts a young child standing on a surface. The child is dressed in a short-sleeved shirt and shorts, with socks and shoes. The child's hair is curly and appears to be blonde. The background of the photograph is plain and unobtrusive, likely a studio setting. The photograph is in black and white, and the lighting is even, with no harsh shadows or bright highlights. The child's expression is one of curiosity or interest, as they look down at their feet. The photograph is sharp and clear, with good contrast between the light and dark areas. Overall, the photograph captures a candid moment of a young child exploring their surroundings. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/17l.jpg \n",
      " The photograph depicts a woman standing in a relaxed pose, with her right hand on her hip and her left hand holding a hose. She is wearing a short, sleeveless dress that appears to be white. The background of the photograph is a simple, unobtrusive setting that does not distract from the subject. The lighting in the photograph is even and natural, highlighting the woman's features and the details of her dress. The photograph is well-composed, with the woman centered in the frame and the hose leading the viewer's eye to her. Overall, the photograph is a well-executed portrait of a woman in a casual, everyday setting. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/286t.jpg \n",
      " The photograph depicts a woman standing outdoors, dressed in a white dress. She is positioned in front of a white picket fence, which is partially open, revealing a brick wall behind it. The background features a lush, green garden with various plants and trees. The woman is holding onto the fence with one hand, and her other hand is resting on her hip. She is looking directly at the camera, with a slight smile on her face. The photograph is in black and white, and the lighting appears to be natural, with soft shadows. The overall mood of the photograph is calm and serene. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/287g.jpg \n",
      " The photograph depicts two individuals, one male and one female, both dressed in white pants and black tops. The woman is seated on a windowsill, with her legs crossed and her head resting on her hand. The man is standing next to her, leaning against the wall with his arms crossed. The background features a large window with a grid pattern, and the overall tone of the image is black and white. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/3189j.jpg \n",
      " The photograph depicts a dirt road that stretches into the distance, flanked by grassy fields. The road curves slightly as it approaches the horizon, where it meets a line of hills or mountains. The sky is clear, with no visible clouds. There are no vehicles or people on the road, and no buildings or other structures are visible. The overall impression is of a rural, isolated area. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/4911d.jpg \n",
      " The photograph depicts a rustic scene, likely from a rural setting. In the foreground, there is a thatched-roof hut, suggesting traditional construction methods. The thatched roof is a key feature, indicating a style of architecture that utilizes natural materials for insulation and weather protection. The hut is surrounded by a few trees, which provide a sense of seclusion and connection to nature. The trees are relatively tall and have a sparse arrangement, allowing sunlight to filter through and illuminate the scene. The ground appears to be a dirt path or open area, with no visible vegetation, indicating a well-trodden or cleared space. The overall atmosphere of the photograph is serene and pastoral, capturing a moment of simplicity and tranquility in a rural environment. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/4785a.jpg \n",
      " The photograph depicts a woman with a serene expression, her head slightly tilted to the side. She is adorned with a headdress that appears to be made of feathers, adding an element of elegance to her appearance. The background of the photograph is blurred, ensuring that the focus remains solely on the woman. The image is framed within a border, and the page it is placed on is slightly yellowed, suggesting that the book has been in use for some time. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://samplebook.photos/img/4793a.jpg \n",
      " The photograph depicts a man in a striped shirt, who appears to be in a state of distress. He is holding a bottle, which he is about to throw. The man is wearing a hat, and his facial expression suggests that he is experiencing a great deal of pain. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "responses_nvlm = {}\n",
    "\n",
    "for url in urls:\n",
    "    response = get_response(url)\n",
    "    print(url,\"\\n\",response,\"\\n\\n\")\n",
    "    responses_nvlm[url] = {'nvidia/NVLM-D-72B':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdcc6ebc-3fc3-405a-abf8-55aa02ba01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7199d0ae-ac3d-4124-bf0e-481f97ec47f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"responses_nvlm.pkl\", \"wb\") as f:\n",
    "    pickle.dump(responses_nvlm, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
