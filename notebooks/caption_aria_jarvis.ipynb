{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f6082a-e816-461c-a220-47d65cd4c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers==4.45.0 accelerate==0.34.1 sentencepiece==0.2.0 torchvision requests torch Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec534f3-2eda-487d-851b-f7e6552d30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d01dde-5df2-433a-b212-dc58e43f843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install grouped_gemm==0.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43303d54-f880-4aab-a088-192e92df4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5495ef-7adb-401c-9758-0b083b415f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id_or_path = \"rhymes-ai/Aria\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81d6d0-4867-4594-989e-d411a1b84a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id_or_path, device_map=\"auto\", torch_dtype=torch.bfloat16, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1cfa5f-2716-4dda-b510-f9122a7d0027",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id_or_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3c9f6-4a45-48bd-a584-bac9fdee0aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    " 'https://samplebook.photos/img/4786a.jpg',\n",
    " 'https://samplebook.photos/img/284v.jpg',\n",
    " 'https://samplebook.photos/img/3193c.jpg',\n",
    " 'https://samplebook.photos/img/948d.jpg',\n",
    " 'https://samplebook.photos/img/3191i.jpg',\n",
    " 'https://samplebook.photos/img/4788oo.jpg',\n",
    " 'https://samplebook.photos/img/2086d.jpg',\n",
    " 'https://samplebook.photos/img/4781r.jpg',\n",
    " 'https://samplebook.photos/img/5521n.jpg',\n",
    " 'https://samplebook.photos/img/2073cc.jpg',\n",
    " 'https://samplebook.photos/img/2085b.jpg',\n",
    " 'https://samplebook.photos/img/4782c.jpg',\n",
    " 'https://samplebook.photos/img/4783v.jpg',\n",
    " 'https://samplebook.photos/img/4912gg.jpg',\n",
    " 'https://samplebook.photos/img/304h.jpg',\n",
    " 'https://samplebook.photos/img/2078i.jpg',\n",
    " 'https://samplebook.photos/img/2077q.jpg',\n",
    " 'https://samplebook.photos/img/3192h.jpg',\n",
    " 'https://samplebook.photos/img/904x.jpg',\n",
    " 'https://samplebook.photos/img/4792b.jpg',\n",
    " 'https://samplebook.photos/img/5301p.jpg',\n",
    " 'https://samplebook.photos/img/5207j.jpg',\n",
    " 'https://samplebook.photos/img/1007p.jpg',\n",
    " 'https://samplebook.photos/img/17l.jpg',\n",
    " 'https://samplebook.photos/img/286t.jpg',\n",
    " 'https://samplebook.photos/img/287g.jpg',\n",
    " 'https://samplebook.photos/img/3189j.jpg',\n",
    " 'https://samplebook.photos/img/4911d.jpg',\n",
    " 'https://samplebook.photos/img/4785a.jpg',\n",
    " 'https://samplebook.photos/img/4793a.jpg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54064ee-50b6-4f73-9420-400d29bf74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'There are two objects in this image. One is a color checker, and the other is a photographic sample book, open to a page containing a photograph. Give a detailed description of the photograph.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4838d-3e0e-41fa-b4c7-233b574e34c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(url):\n",
    "    \n",
    "    image = Image.open(requests.get(url, stream=True).raw)\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"text\": None, \"type\": \"image\"},\n",
    "                {\"text\": prompt, \"type\": \"text\"},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(text=text, images=image, return_tensors=\"pt\")\n",
    "    inputs[\"pixel_values\"] = inputs[\"pixel_values\"].to(model.dtype)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.inference_mode(), torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1024,\n",
    "            stop_strings=[\"<|im_end|>\"],\n",
    "            tokenizer=processor.tokenizer,\n",
    "            do_sample=True,\n",
    "            temperature=0.9,\n",
    "        )\n",
    "        output_ids = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "        result = processor.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea326e-8e17-4bbd-8665-1f53b6e0084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_aria = {}\n",
    "\n",
    "for url in urls:\n",
    "    response = get_response(url)\n",
    "    print(url,\"\\n\",response,\"\\n\\n\")\n",
    "    responses_aria[url] = {'rhymes-ai/Aria':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af824d-2934-45ef-bb5e-5c8ee275b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea666719-c3b7-443a-9777-48f407a26f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"responses_aria.pkl\", \"wb\") as f:\n",
    "    pickle.dump(responses_aria, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
